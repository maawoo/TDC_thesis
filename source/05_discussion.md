# Discussion

The following discussion is divided into three sections. Section @sec:usability-assessment discusses the usability of the initial implementation of the TDC in regard to the presented use cases and integrated datasets, while also mentioning some possible improvements that are readily available. Section @sec:implementation-assessment focuses on technical aspects of the implementation that are related to ARD in general and the Open Data Cube. Finally, Section @sec:outlook provides an outlook on how the ARDCube tool could be extended, as well as the possible usage of the TDC at the Department of Earth Observation at the Friedrich-Schiller-University Jena.  



## Usability Assessment

By carrying out the use cases described in Section @sec:use-cases the usability of the initial implementation of the TDC could be assessed and possible improvements identified. The computation of per-pixel observations were a particular important aspect of the assessment. Even though the calculation of the sum of valid observations is rather simple, the underlying logistics of such a computation is not. This is especially the case if a very large volume of data is involved, which furthermore, is heterogeneous in nature (i.e., variability in spatial and temporal coverage). Various factors can have an influence on the performance and might only be apparent or lead to problems when a computation is performed at scale, as opposed to only using a small subset of the data. 

Fortunately, no significant issues were observed during the per-pixel computations of the TDC. In addition, some important aspects could be tested beforehand that are related to the parallel computing library Dask. No universal set of parameters exists that is always resulting in optimal performance. As the tests in Section @sec:performance-considerations have demonstrated, however, the available resources provided by Dask can easily be used to diagnose problems and adjust parameters accordingly. The visualization of diagnostics and insights as an interactive dashboard is a great way to reduce abstractness and the sense of working with a *black box*.     

The results of computing valid observations per pixel for the entire extent of the TDC provide valuable information about the temporal and spatial characteristics of the datasets. On one hand, inappropriate parameterization during the processing of ARD can be identified, such as a too large buffer for cloud, cloud-shadow and snow detection. Optimal parameters should of course be determined beforehand by first processing a smaller subset of the dataset. However, a visualization of the end product can reveal inconsistencies in the underlying data that might otherwise remain unnoticed. Furthermore, it can be used in support of performing time-series analysis. An area of interest can, for example, be located in a region of significantly fewer observations due to the orbit paths of the EO satellites. In addition, valid data points might be removed unintentionally when applying masks derived from the QAI band, as the algorithm used during processing can include false-positive detections [@Frantz2015; @Frantz2018]. It is important to consider these aspects before conducting an analysis or at least being aware of possible impacts. Having access to this information prior to the analysis or being able to easily generate and visualize it for a particular study area can be very beneficial. 

The study area of the Roda forest is located in a region of fewer observations for the Sentinel-2A/B and descending Sentinel-1A/B datasets. Nevertheless, the amount of data points were sufficient to conduct the time-series analysis in the form that was intended and the potential of using the TDC could successfully be demonstrated.

The correlation between decreasing NDVI and VH backscatter values in some, presumably agricultural, areas (Figure @fig:roda_analysis_1), is difficult to quantify without having any information about the crop type and cultivation cycle and is not a focus of this use case. As already described in Section @sec:roda_results, the highlighted forest area contains patches that seem to have degraded over the observed timespan. Some of these patches are accompanied by increased VH backscatter values to the northeast, which correlates with the look direction of the ascending orbit pass of the Sentinel-1A/B satellites. This effect could be caused by the clearing of forest areas, as the backscatter increase might be due to a double-bounce mechanism along the newly created forest edge [@Villard2007]. Additionally, an opposite shadow effect can sometimes be observed, which has been utilized by @Bouvet2018 to detect deforestation. However, a shadow effect does not seem to be visible in this case.  

The significant decrease of NDVI values for point A (Figure @fig:roda_analysis_2) and continuously low values thereafter, further support the assumption that at least some of these patches have not simply degraded but rather been cleared. The timing of the sharp drop-off of the NDVI time-series at the beginning of May 2018 suggests that the clearing happened at the beginning of the 2018 drought [@Schuldt2020]. A reason for such a clearing could be to prevent the spread of a bark beetle infestation. Damage caused by insect infestations has developed into the main reason for logging in German forests [@Destatis2020] and other regions worldwide, hence increasing the need for monitoring solutions that use time-series information derived from EO data [@Hollaus2019; @FernandezCarrillo2020].

The lack of seasonality in the NDVI time-series for point B might indicate that a coniferous evergreen forest is present in the area [@She2015]. A seasonal variation of the VH backscatter time-series on the other hand is plausible as the signal is influenced by the water content of the foliage, which changes over the year according to water availability [@Dubois2020]. The ascending and descending signals appear to show a more pronounced division during the summer periods 2018 and 2019 in comparison to 2017. As the orbits pass over the area during different times of the day (late afternoon for ascending; early morning for descending orbit), the diurnal difference of the backscatter signals could indicate drought related water stress [@SteeleDunne2012] and needs to be investigated further.

- Appendix stuff -> possible drought legacy effects?

Data points from the Sentinel-2A/B and Landsat 8 datasets have been combined to calculate the median NDVI differences seen in Figure @fig:roda_analysis_1 (and APPENDIX!). This combined usage is not trivial, as both sensors cover slightly different spectral wavelengths. While effort is being made to create harmonized data products from both sensors [@Claverie2018; @Scheffler2020], ARD products that have been created with FORCE are not yet harmonized during processing. Therefore, this aspect needs to be considered when similar time-series analysis are conducted using the TDC and the appropriateness of aggregating data points from different datasets ultimately depends on the study objective.     

Currently, the Level-1C data products of the Sentinel-2 mission have a multi-temporal geometric uncertainty of around 12 m [@Gascon2017], which can be a negative influence on time-series analyses. While a geometric refinement is currently being implemented by ESA to improve the accuracy [@ESA2021], it is not clear if the reprocessing of past datasets is planned. A coregistration option has already been implemented into FORCE L2PS (see Figure @fig:force). @Rufin2020 describe the algorithm used in more detail, which ultimately leverages base images created from the Landsat 8 near-infrared band to improve the multi-temporal geometric uncertainty of the processed Sentinel-2 ARD product to an average of around 4.4 m. This processing option requires some preparation steps but is readily available in the version of FORCE utilized in this work. The quality of time-series can thus be improved for future analyses performed with the TDC by reprocessing the Sentinel-2A/B dataset.  

The Sentinel-1A/B datasets were already provided in an ARD format and have been processed using an SRTM 1 arcsecond DEM (see Section @sec:sar-satellite-data). As @Truckenbrodt2019 describe in their work, large discrepancies can sometimes be observed between different openly available DEM options, such as SRTM. This can affect the quality of the topographic normalization during processing and ultimately the time-series analysis of individual pixels. Similarly to the Sentinel-2A/B dataset, it might be worthwhile to reprocess the dataset to further improve the data quality in regard to time-series analysis. The LiDAR-derived DEM utilized during the processing of the Sentinel-2A/B and Landsat 8 datasets could be used after a similar quality assessement as described by @Truckenbrodt2019 has been performed.  

In conclusion, the usability of the current implementation of the TDC has successfully been demonstrated with the performed use cases. The quality of all datasets is appropriate for time-series analysis but could be further improved with readily available processing options and ancillary data. Access to the indexed ARD products via the ODC Python API works without any issues or additional preparation steps. For example, no reprojection and resampling of the data has to be performed during data loading as all datasets are stored in a common projection and the same non-overlapping tiling scheme. The utilization of a continental projection, such as GLANCE7, can be additionally advantageous in the future by facilitating interoperability with other study areas in the same region if the same projection is used.   

The existing ecosystem of Python packages surrounding the core packages Xarray and Dask is steadily growing and has been adopted by a variety of scientific fields and institutions [e.g., @EynardBontemps2019]. The aspect of adoption should not be neglected in connection with open-source software projects, as it can ensure long term support of development. Various packages in this ecosystem can pave the way to more advanced types of analyses than demonstrated here. The Dask extension dask-ml [@DaskML-Software], for example, provides access to scalable machine learning by leveraging the popular Python library Scikit-Learn [@Pedregosa2011]. Furthermore, packages that might not be directly related to the ecosystem can easily be integrated into an analysis, such as the Roda use case, to provide additional information like climatic time-series data from weather stations located in the study area [@Wetterdienst-Software]. 



## Implementation Assessment


### Analysis Ready Data {#sec:ard_discussion}

Processing optical and SAR data with the software components integrated in the ARDCube tool produces datasets that can directly be used in an analysis and hence be designated as ARD products. However, a formal assessment of how well these products comply with the current CARD4L specifications described in Section @sec:card4l, has neither been done in the course of this work, nor by the developers of FORCE or pyroSAR. However, @Truckenbrodt2019 acknowledge that this is a future goal along with a relevant extension of the pyroSAR software and at the time of writing the official CARD4L website already lists FORCE as an ARD resource.

Various aspects that are related to ARD were taken into account while developing the ARDCube tool and implementing the TDC, but were not actively adjusted or changed. For the data format of both optical and SAR datasets, for example, the current setup solely relies upon which GeoTIFF specifications are defined by FORCE for the output files. @Alberti2018 demonstrates that GeoTIFF specifications such as the compression algorithm can have a significant impact on read and write speeds, as well as the ratio of compression and therefore storage size. Moreover, the internal tiling of the files affects the performance of only accessing a small part of each file, which is done repeatedly when a time-series of a pixel is retrieved, for example. These aspects need to be considered when large volumes of EO data are supposed to be handled during an analysis. Furthermore, new raster data formats have emerged in recent times, including Cloud Optimized GeoTIFF (COG) and Zarr, which provide their own set of specifications, as well as advantages and disadvantages [@Yee2020]. 

In regard to the TDC, the current approach works quite well as demonstrated with the per-pixel computations (Section @sec:per-pixel-computations). Therefore, any changes of the data format need to be justified, as existing datasets and the processing workflows would need to be adjusted. There appears to be a lack of literature in this regard, so an assessment where different format options are compared in the same computational setup could be valuable.

Similar to the data format, the handling of metadata needs further consideration. As mentioned in Sections @sec:optical-satellite-data and @sec:sar-satellite-data, additional metadata is stored in each GeoTIFF file by FORCE, whereas the SAR datasets were provided with separate metadata files. At present, the ARDCube tool does not include any ancillary functionality or leverages relevant features provided by pyroSAR, for example, to organize the available metadata. Another layer of complexity is added by the ODC, which requires its own set of metadata files in the form of dataset documents (see Section @sec:odc_methods), which currently only contain necessary information to ensure that the ODC Python API is operable. 

The CARD4L specifications list *machine readability* as one of the minimum requirements in terms of the handling of metadata, which is satisfied in all cases mentioned. Nevertheless, a uniform solution to organize and easily access the metadata of all datasets would be desirable. The SpatioTemporal Asset Catalog (STAC) specification [@STAC] could provide a viable and standardized solution, which potentially will be implemented into the ODC in the near future [@ODC-Docs]. It uses a similar approach as already used by the ODC in the form of higher-level (*Product Definition* in ODC; *Collections* in STAC) and lower-level metadata documents (*Dataset Documents* in ODC; *Items* in STAC). Furthermore, the STAC specification is an open-source project that is already being supported by a large community with additional and openly available tools being developed, such as the STAC Browser [@STACBrowser-Software].

A final aspect to be briefly discussed is the availability of auxiliary data products, which are specified by CARD4L as *Per-Pixel Metadata*. The QAI band produced by FORCE for the optical datasets is one such product already used in the initial implementation of the TDC. It provides valuable information during analyses and can be used to filter a time-series for clear-sky observations as demonstrated in Section @sec:per-pixel-computations. For the SAR datasets on the other hand, no auxiliary data products have currently been created and integrated into the TDC. The Normalized Radar Backscatter PFS of CARD4L lists, amongst others, the provision of a local incident angle image as a minimum requirement. In addition, @Truckenbrodt2019 recommend that a map of geometrical distortion (e.g., layover and radar shadow) should also be provided when a Sentinel-1 EODC is created. Both products can be produced during processing with pyroSAR's SNAP API and integrating them into the TDC could be of great value for future analyses and the development of new methodologies. 


### Open Data Cube {#sec:odc_discussion}

@Gentemann2021 state that a paradigm shift is happening in science, as data, software, and computational resources are moving towards cloud-based solutions. However, a lot of challenges are yet to be solved and HPC systems will remain important tools in many research institutions while technologies related to this shift are increasingly being adopted [@Abernathey2020]. In conjunction with this trend, various cloud-based EO platforms have emerged. As described by @Giuliani2019, such platforms potentially come with their own set of drawbacks and limit the control and flexibility of users. These aspects are particularly important in regard to research departments where existing computational resources are often utilized to perform data-intensive workloads and supplementary data sources might need to be integrated into analyses. Therefore, the ODC has been an appropriate choice for the initial implementation of the TDC at the Department of Earth Observation at the Friedrich-Schiller-University Jena.  

The complete setup of an operational EODC based on the ODC software library is still rather complex, as a lot of factors need to be considered and both IT and remote sensing knowledge is required. This problem has also been pointed out by @Giuliani2020b and @HernandezLopez2021 and is limiting the adoption of this technology. A possible solution has been proposed by @Giuliani2020b in the form of the Docker-based “Data Cube on Demand” (DCoD). This project intends to cover the entire cycle of downloading and processing EO data for a particular area of interest and creating an ODC instance. Being open-source with possible improvements and development of the proposed project through external contributors has been named by the authors as an additional advantage, but the DCoD has yet to be made public. 

The ARDCube project developed in the course of this work intends to solve the same problem as the DCoD, while focusing on the deployment on HPC systems. As mentioned in Section @sec:containerization, Singularity has been selected as the containerization solution for this reason. Docker usually prevails as the most popular solution, which is also the case in regard to ODC. Various Docker-based ODC projects exist, whereas none have yet been found that are based on Singularity. The path to working out an appropriate solution for the TDC has not been straightforward, as the current documentation of ODC is lacking in clear guidance in this regard, resulting in confusion amongst ODC users.  

It has already been mentioned in Section @sec:ard_discussion that ODC is moving towards integrating the STAC specification. Similarly, the database backend is likely to change at some point in the future, as various proposals have been made to either replace the ODC database API [@Kouzoubov2019], which is currently relying on PostgreSQL, or to add support for alternative backends [@Woodcock2019; @Dhar2021]. However, it is yet unknown if and when these changes are implemented into the core library of ODC. 

A project that not only shares some of the same core Python packages as ODC but also drives their development forward, is Pangeo [@Pangeo-Web]. This community-driven project aims to enable Big Data geoscience research through an ecosystem of open-source software packages, such as the aforementioned Xarray, Dask and JupyterLab, and is already being used with large volumes of EO data as demonstrated by @Kellndorfer2021. As the ODC is still in a transformative state of development, it might be worthwhile to explore alternative solutions that can be used to organize and access the EO datasets of the TDC. The Pangeo software ecosystem is complemented by projects like Intake-STAC [@Hamman2020] and StackSTAC [@StackSTAC-Software], and might already facilitate the development of an architecture that is similar to what is being envisaged for the future of the ODC. However, a more in-depth comparison would be needed to identify advantages and disadvantages, as well as any technical limitations that can be present at the current stage of development.   

@Coetzee2020 have discussed the importance of communities that ultimately drive open-source projects forward in their development and that sustaining such a community can be challenging. This aspect seems to be an important challenge for the future development of the ODC. Even though it is one of the pioneering projects regarding EODCs and has been deployed in various countries and regions worldwide, it still lacks an appropriate space for the community of users to engage sustainably. However, this challenge is being addressed, since the ODC has recently joined OSGeo (Open Source Geospatial Foundation) as a community project [@OSGeo-ODC] and is being supported via the *Open Earth Alliance* community activity of GEO (Group on Earth Observations) [@Gowda].

- Abschließender Absatz im Zusammenhang mit TDC (so wie in usability assessment ungefähr)



## Outlook

The ARDCube tool developed in the course of this work successfully facilitated the implementation of the TDC on the TerraSense HPC system. While the usage still requires a certain degree of IT and remote sensing knowledge, it can ease the process of creating an EODC for a region of interest and could potentially be used by other individuals or research departments. For this reason, the aim is to further development the ARDCube tool and extend its functionality.

A particular area of improvement that might be of great potential is reproducibility. @Abernathy2020 have stated that the *“reproducibility of data science projects requires open access to at least three elements: the code, the software environment, and the data.”* (p. 3). They propose the concept of cloud-native data repositories, which could enable the reproducibility of scientific results that depend on large volumes of data and computational resources. However, various challenges remain that limit adoption of cloud computing in scientific research (e.g., funding). One of the few possible options for reproducibility in such cases is the recreation of the necessary software environment and datasets, which can then be used with code that has been shared via online platforms such as GitHub. Recreating a software environment and reprocessing data to the specific format necessary to reproduce scientific results comes with its own challenges, but can be eased by using containerization, for example. The ARDCube tool manages multiple containerized software components that each depend on a different parameterization. A possible improvement of the tool could therefore be the automatic creation of a *recipe* that defines all necessary information to recreate an EODC. This includes information such as the query used to download level-1 data, processing parameters for ARD generation, and software versions and dependencies to recreate the software environment. The recipe itself could be realized in the form of a simple machine-readable file (e.g., in the JSON format) or by utilizing an existing workflow management system like Snakemake [@Moelder2021]. 

Various improvements of the TDC are possible in the near future and some have already been discussed in the previous sections regarding the EO datasets that have already been implemented (Landsat 8, Sentinel-2A/B and Sentinel-1A/B). The volume of data can be further extended by processing the data from other sensors of the Landsat archive via FORCE, which opens up the possibility to investigate time-series that span multiple decades. Other SAR datasets could be implemented as well via existing format drivers provided by pyroSAR. This would require some adjustments of the ARDCube tool, however, whereas processing of data from other Landsat sensors is immediately possible. Furthermore, the usage of Sentinel-1 SLC (Single Look Complex) data in EODCs is being explored [@SAR2CUBE]. This would likely be a valuable addition to the TDC and enable the development of new methodologies to analyse this kind of SAR data.    

Once the volume of data has been extended temporally and in terms of additional sensors, the TDC could be kept up-to-date by automating the ARDCube workflows on TerraSense with a set of cron jobs [@cron-Software]. This could further be extended by automatically deriving information products from the TDC, which could be made accessible to the public through interactive web applications. The ODC ecosystem is already being extended in this regard [@Gowda2020], so the development of such an application would not have to be done from the ground up. An example of a near real-time data stream that uses a Sentinel-1 EODC for flood monitoring in Austria is presented by @Wagner2020. 

Lastly, access to the TDC needs be improved to facilitate the efficient usage by multiple users and to avoid the possible misuse or accidental blocking of computational resources on TerraSense. This would especially be relevant in case working with the TDC is integrated into any existing lectures where a number of students need access simultaneously. Fortunately, solutions already exist that can also be adapted on TerraSense for the TDC, such as JupyterHub [@Thomas2021]. A possible outlook of how a further integration of the TDC could look like both in regard to research and teaching, is provided by [@eo2cube] and their integration of EODCs at the Remote Sensing Department of the University of Würzburg. Moreover, an increase of collaboration and sharing of knowledge between the departments could be of great potential. This might include an effort to improve the interoperability between existing EODCs, which has been named by @Giuliani2019 as an essential challenge in order to prevent individual EODCs to become silos of information.
